#File version 2.0
Setup Infra:
# Copy both files at once (replace paths and IP)
scp -i C:\path\to\vm_ssh_key C:\path\to\setup-infra.yml C:\path\to\inventory.ini <USER>@<PUBLIC_IP>:/home/<USER>/
ls -l setup-infra.yml inventory.ini

ansible-playbook -i inventory.ini setup-infra.yml

Task 1:
1. SSH to control.example.com (Local)
ssh -i vm_ssh_key adminuser@20.186.153.18
Run: (linux)
sudo apt update
sudo apt install -y ansible
1.1. (linux)
mkdir -p /home/adminuser/ansible
1.2. (windows)
scp -i .\Ansible\vm_ssh_key -r .\Ansible\ adminuser@20.186.153.18:/home/adminuser/ansible/
1.3. (linux)
# Navigate to the directory containing your key
cd ~/ansible/Ansible/

# Set strict permissions (only owner can read/write)
chmod 600 vm_ssh_key

# Verify permissions (should show -rw-------)
ls -l vm_ssh_key
2. Test response using ping:
ansible -i inventory.ini nodes -m ping -u adminuser
ansible -i inventory.ini nodes -m command -a "uname -a"
ansible -i inventory.ini nodes -m command -a "uptime"
ansible -i inventory.ini nodes -m apt -a "name=htop state=present" --become

3. Add managed nodes:
Edit your inventory file (../Ansible/inventory.ini) and add:
[managed_nodes]
node1.example.com
node2.example.com


4. Verify with ad hoc commands
ansible -i inventory.ini managed_nodes -m setup -a "filter=ansible_hostname"
ansible -i inventory.ini managed_nodes -m setup -a "filter=ansible_distribution*"

5. Create a playbook for network interfaces
Create a new file called network_interfaces.yml with:
---
- name: Gather and display network interfaces
  hosts: all
  gather_facts: true
  tasks:
    - name: Display network interfaces
      debug:
        msg: "Host {{ inventory_hostname }} has these interfaces: {{ ansible_interfaces }}"
        
    - name: Display detailed IP information
      debug:
        var: ansible_facts.network_interfaces

Run: 
ansible-playbook -i inventory.ini network_interfaces.yml
ansible-playbook -i inventory_file playbook.yml


Task 2:
1. Create the role structure
First, on your control node (control.example.com), create the role structure:

mkdir -p roles/common/{defaults,tasks,handlers}
touch roles/common/{defaults,tasks,handlers}/main.yml

2. Set up the role files
roles/common/defaults/main.yml:

# Default variables for the common role
required_packages: []  # Empty by default
disable_selinux: false  # Don't disable SELinux by default

roles/common/tasks/main.yml:
---
# Main tasks file for common role
- name: Include package installation tasks
  include_tasks: packages.yml
  when: required_packages | length > 0

- name: Include SELinux tasks
  include_tasks: selinux.yml
  when: disable_selinux

  roles/common/tasks/packages.yml:
---
# Install required packages
- name: Install required packages
  apt:
    name: "{{ required_packages }}"
    state: present
    update_cache: yes
  become: yes

  roles/common/tasks/selinux.yml:
---
# Disable SELinux
- name: Check SELinux status
  command: sestatus
  register: selinux_status
  changed_when: false
  ignore_errors: yes

- name: Disable SELinux if enabled
  block:
    - name: Disable SELinux
      selinux:
        state: disabled
      become: yes
      register: selinux_disabled

    - name: Reboot if SELinux was disabled
      reboot:
        msg: "Reboot initiated after disabling SELinux"
        connect_timeout: 5
        reboot_timeout: 600
        pre_reboot_delay: 0
        post_reboot_delay: 30
      become: yes
      when: selinux_disabled is changed
  when: "'disabled' not in selinux_status.stdout"

roles/common/handlers/main.yml:
---
# Handlers for common role
- name: restart sshd
  service:
    name: sshd
    state: restarted
  become: yes

3. Create common_playbook.yml in your main directory:
---
- name: Apply common configuration to all nodes
  hosts: managed_nodes
  become: yes
  vars:
    required_packages:
      - curl
      - lsof
      - mc
      - nano
      - tar
      - unzip
      - vim
      - zip
    disable_selinux: true  # Set to false if you don't want to disable SELinux

  roles:
    - common

4. execute the playbook with:
ansible-playbook -i inventory.ini common_playbook.yml

Verification:
1. Check installed packages:
ansible -i inventory.ini managed_nodes -m command -a "dpkg -l curl lsof mc nano tar unzip vim zip"

2. Check SELinux status:
ansible -i inventory.ini managed_nodes -m command -a "sestatus"

3. Check if nodes were rebooted (look at uptime):
ansible -i inventory.ini managed_nodes -m command -a "uptime"